{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "155mini3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc1t061Kkvt9",
        "colab_type": "text"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju22vPp9kwmm",
        "colab_type": "code",
        "outputId": "f30aefdb-6d41-4a41-ddea-060b4e28288a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcug_-xHlh-f",
        "colab_type": "code",
        "outputId": "4db5fb43-7d63-42c8-c911-ff216bfb0f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd 'drive/My Drive/155mini3'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/155mini3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NysNQlbVlvP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "\n",
        "from HMM import unsupervised_HMM\n",
        "from HMM_helper import (\n",
        "    text_to_wordcloud,\n",
        "    states_to_wordclouds,\n",
        "    parse_observations,\n",
        "    sample_sentence,\n",
        "    visualize_sparsities,\n",
        "    animate_emission,\n",
        "    get_syllable_dict, \n",
        "    get_rhyme_dict,\n",
        "    sample_rhyming_sonnet\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEG4wz6XwcZq",
        "colab_type": "text"
      },
      "source": [
        "# Build + Train LSTM\n",
        "\n",
        "based on: https://blog.usejournal.com/how-to-develop-a-character-based-neural-language-model-99c18de1d4d2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8wN4IZVC0La",
        "colab_type": "code",
        "outputId": "2bd431b2-6f3e-4013-b3c9-815896360664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        " \n",
        "# save tokens to file, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        " \n",
        "# load text\n",
        "raw_text = load_doc('data/shakespeare.txt')\n",
        " \n",
        "# clean\n",
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n",
        " \n",
        "# organize into sequences of characters\n",
        "length = 40\n",
        "sequences = list()\n",
        "for i in range(length, len(raw_text)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = raw_text[i-length:i+1]\n",
        "\t# store\n",
        "\tsequences.append(seq)\n",
        "print('Total Sequences: %d' % len(sequences))\n",
        " \n",
        "# save sequences to file\n",
        "out_filename = 'char_sequences.txt'\n",
        "save_doc(sequences, out_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 94141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G8kZfEqwokd",
        "colab_type": "code",
        "outputId": "2e7e1be6-d350-4d42-e02b-9d50ea176daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "\n",
        "from numpy import array\n",
        "import numpy as np\n",
        "from pickle import dump\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Lambda\n",
        "\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load\n",
        "in_filename = 'char_sequences.txt'\n",
        "raw_text = load_doc(in_filename)\n",
        "lines = raw_text.split('\\n')\n",
        "\n",
        "# integer encode sequences of characters\n",
        "chars = sorted(list(set(raw_text)))\n",
        "mapping = dict((c, i) for i, c in enumerate(chars))\n",
        "sequences = list()\n",
        "for line in lines:\n",
        "\t# integer encode line\n",
        "\tencoded_seq = [int(mapping[char]) for char in line]\n",
        "\tsequences.append(encoded_seq)\n",
        "  # print(line)\n",
        "print(len(encoded_seq))\n",
        "# length = max(map(len, sequences))\n",
        "# sequences= array([xi+[0]*(length-len(xi)) for xi in sequences])\n",
        "# vocabulary size\n",
        "vocab_size = len(mapping)\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "\n",
        "# separate into input and output\n",
        "sequences = array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
        "X = array(sequences)\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "41\n",
            "Vocabulary Size: 71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9lK7JoXEId2",
        "colab_type": "code",
        "outputId": "80ffaf98-8316-4700-c442-af57910d9e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "\n",
        "model.fit(X, y, epochs=40, verbose=2)\n",
        "\n",
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the mapping\n",
        "dump(mapping, open('mapping.pkl', 'wb'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 100)               68800     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 71)                7171      \n",
            "=================================================================\n",
            "Total params: 75,971\n",
            "Trainable params: 75,971\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/40\n",
            " - 238s - loss: 2.4766 - acc: 0.3153\n",
            "Epoch 2/40\n",
            " - 239s - loss: 2.0825 - acc: 0.3986\n",
            "Epoch 3/40\n",
            " - 242s - loss: 1.9598 - acc: 0.4262\n",
            "Epoch 4/40\n",
            " - 242s - loss: 1.8829 - acc: 0.4453\n",
            "Epoch 5/40\n",
            " - 238s - loss: 1.8264 - acc: 0.4602\n",
            "Epoch 6/40\n",
            " - 244s - loss: 1.7818 - acc: 0.4698\n",
            "Epoch 7/40\n",
            " - 251s - loss: 1.7480 - acc: 0.4781\n",
            "Epoch 8/40\n",
            " - 235s - loss: 1.7150 - acc: 0.4860\n",
            "Epoch 9/40\n",
            " - 235s - loss: 1.6818 - acc: 0.4932\n",
            "Epoch 10/40\n",
            " - 238s - loss: 1.6498 - acc: 0.5024\n",
            "Epoch 11/40\n",
            " - 240s - loss: 1.6234 - acc: 0.5079\n",
            "Epoch 12/40\n",
            " - 244s - loss: 1.6005 - acc: 0.5137\n",
            "Epoch 13/40\n",
            " - 235s - loss: 1.5794 - acc: 0.5196\n",
            "Epoch 14/40\n",
            " - 242s - loss: 1.5623 - acc: 0.5238\n",
            "Epoch 15/40\n",
            " - 252s - loss: 1.5479 - acc: 0.5275\n",
            "Epoch 16/40\n",
            " - 245s - loss: 1.5332 - acc: 0.5309\n",
            "Epoch 17/40\n",
            " - 236s - loss: 1.5176 - acc: 0.5361\n",
            "Epoch 18/40\n",
            " - 243s - loss: 1.5043 - acc: 0.5396\n",
            "Epoch 19/40\n",
            " - 243s - loss: 1.4917 - acc: 0.5430\n",
            "Epoch 20/40\n",
            " - 244s - loss: 1.4797 - acc: 0.5471\n",
            "Epoch 21/40\n",
            " - 249s - loss: 1.4678 - acc: 0.5480\n",
            "Epoch 22/40\n",
            " - 247s - loss: 1.4558 - acc: 0.5519\n",
            "Epoch 23/40\n",
            " - 237s - loss: 1.4449 - acc: 0.5548\n",
            "Epoch 24/40\n",
            " - 234s - loss: 1.4344 - acc: 0.5583\n",
            "Epoch 25/40\n",
            " - 236s - loss: 1.4248 - acc: 0.5601\n",
            "Epoch 26/40\n",
            " - 236s - loss: 1.4140 - acc: 0.5638\n",
            "Epoch 27/40\n",
            " - 239s - loss: 1.4045 - acc: 0.5654\n",
            "Epoch 28/40\n",
            " - 237s - loss: 1.3955 - acc: 0.5680\n",
            "Epoch 29/40\n",
            " - 238s - loss: 1.3860 - acc: 0.5708\n",
            "Epoch 30/40\n",
            " - 232s - loss: 1.3774 - acc: 0.5733\n",
            "Epoch 31/40\n",
            " - 230s - loss: 1.3679 - acc: 0.5767\n",
            "Epoch 32/40\n",
            " - 227s - loss: 1.3598 - acc: 0.5770\n",
            "Epoch 33/40\n",
            " - 228s - loss: 1.3512 - acc: 0.5807\n",
            "Epoch 34/40\n",
            " - 231s - loss: 1.3431 - acc: 0.5832\n",
            "Epoch 35/40\n",
            " - 233s - loss: 1.3352 - acc: 0.5851\n",
            "Epoch 36/40\n",
            " - 236s - loss: 1.3265 - acc: 0.5873\n",
            "Epoch 37/40\n",
            " - 249s - loss: 1.3198 - acc: 0.5901\n",
            "Epoch 38/40\n",
            " - 243s - loss: 1.3124 - acc: 0.5919\n",
            "Epoch 39/40\n",
            " - 241s - loss: 1.3054 - acc: 0.5939\n",
            "Epoch 40/40\n",
            " - 239s - loss: 1.2973 - acc: 0.5966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amn8xkmfeJEO",
        "colab_type": "text"
      },
      "source": [
        "# Generate 14-line poems with different temperatures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7QHheBQy3Z2",
        "colab_type": "code",
        "outputId": "d23eef99-9ea3-47f2-eaf9-862380345389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "model = load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48tX_syac-cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapping = load(open('mapping.pkl', 'rb'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_92FJHRVatG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "# generate a sequence of characters with a language model\n",
        "def generate_seq(model, mapping, seq_length, seed_text, n_chars, n_syllables, temp =None):\n",
        "  in_text = seed_text\n",
        "  # generate a fixed number of characters\n",
        "  while True:\n",
        "      # encode the characters as integers\n",
        "      encoded = [mapping[char] for char in in_text]\n",
        "      # truncate sequences to a fixed length\n",
        "      encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "      # one hot encode\n",
        "      encoded = to_categorical(encoded, num_classes=len(mapping))\n",
        "      # predict character\n",
        "      if temp is None:\n",
        "        yhat = model.predict_classes(encoded, verbose=0)\n",
        "      else:\n",
        "        predictions = model.predict(encoded, verbose=0)[0]\n",
        "        yhat = sample(predictions,temp)\n",
        "      # reverse map integer to character\n",
        "      out_char = ''\n",
        "      for char, index in mapping.items():\n",
        "          if index == yhat:\n",
        "              out_char = char\n",
        "              break          \n",
        "\n",
        "      # append to input\n",
        "      in_text += char\n",
        "\n",
        "      #We only want the new part of the string, not including the original seed text\n",
        "      res = in_text[len(seed_text)+1:-1]\n",
        "      #End when the new text has the correct number of syllables\n",
        "      if len(res) > 0 and nsyl(res) == n_syllables:\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayt0N-88euh8",
        "colab_type": "code",
        "outputId": "2b31ff01-b8c6-4832-af59-3e52cbcff9b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('cmudict')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jym1xRMpesGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#syllable checker\n",
        "from nltk.corpus import cmudict\n",
        "d = cmudict.dict()\n",
        "\n",
        "def nsyl(word):\n",
        "    try:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]]\n",
        "    except KeyError:\n",
        "        #if word not found in cmudict\n",
        "        return syllables(word)\n",
        "\n",
        "def syllables(word):\n",
        "    #referred from stackoverflow.com/questions/14541303/count-the-number-of-syllables-in-a-word\n",
        "    count = 0\n",
        "    vowels = 'aeiouy'\n",
        "    word = word.lower()\n",
        "    if word[0] in vowels:\n",
        "        count +=1\n",
        "    for index in range(1,len(word)):\n",
        "        if word[index] in vowels and word[index-1] not in vowels:\n",
        "            count +=1\n",
        "    if word.endswith('e'):\n",
        "        count -= 1\n",
        "    if word.endswith('le'):\n",
        "        count += 1\n",
        "    if count == 0:\n",
        "        count += 1\n",
        "    return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxHxOAheEpGY",
        "colab_type": "code",
        "outputId": "0d00c66f-dae7-403f-bea8-a54208a5b5ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Generate poem line-by-line\n",
        "total_poem = ['Shall I compare thee to a summer\\'s day?']\n",
        "for i in range(1,11):\n",
        "  total_poem.append(generate_seq(model, mapping, 40, total_poem[i-1], 2000,10,temp=1))\n",
        "for l in total_poem:\n",
        "  print(l)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shall I compare thee to a summer's day?\n",
            "Thus these of a good a himash to\n",
            "nd. 88 So dring my heart is, or virsur see so\n",
            " He gener tom, I some to as tho\n",
            " wasty wo hot every of Tied, A\n",
            " annour engiad in quise and like \n",
            "ven turny in thish althery sover\n",
            " Thou art notriss, and deaphrivious mandra\n",
            "e, And and lovern write refore \n",
            "y a thought Pruisues for this bid such sta\n",
            "s when no shart nor welf and all deserve,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uphUYLuHne83",
        "colab_type": "code",
        "outputId": "8c6869c1-c654-4b29-d62c-03e74cb4ad06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Temperature = 1.5\n",
        "total_poem = ['Shall I compare thee to a summer\\'s day?']\n",
        "for i in range(1,11):\n",
        "  total_poem.append(generate_seq(model, mapping, 40, total_poem[i-1], 2000,10,temp=1.5))\n",
        "for l in total_poem:\n",
        "  print(l)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shall I compare thee to a summer's day?\n",
            "Who eye of cortcy mince anfeello\n",
            "y, On simmous ilte with whe tenst tho\n",
            " king, whe conear; And wort of imponfa\n",
            "now erized her mupy. 30 Th'ne singga\n",
            "ngeds (an owr tinaugis, tell's khe lie ed\n",
            "efk: No, Odm: 3 Me lovities o'ringres\n",
            "eife; awas? Or mely ix morth o\n",
            " that lile, If the staneting kingng tho\n",
            " might, in or. Naching I sauly spity\n",
            " with sweetlequiages, For hang you lavro\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtiYc7KHnJLi",
        "colab_type": "code",
        "outputId": "588d35f8-a356-4cae-e5a7-bd997b0636ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Temperature = 0.75\n",
        "total_poem = ['Shall I compare thee to a summer\\'s day?']\n",
        "for i in range(1,11):\n",
        "  total_poem.append(generate_seq(model, mapping, 40, total_poem[i-1], 2000,10,temp=0.75))\n",
        "for l in total_poem:\n",
        "  print(l)\n",
        "  # print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shall I compare thee to a summer's day?\n",
            "No love in a to thou art mine \n",
            "hade, To make put in thy fall wo\n",
            "th worst no keel, What now was not made thy\n",
            "fair why so greet, The widom my self thy\n",
            "all my love but with thy duts. 44 Who lo\n",
            "e was thou last hor had thy heary wi\n",
            "h dis, And it be noternds and to make \n",
            "he eye ins, Now is an the eyes of the \n",
            "espest, And these wast becomare \n",
            "hou mayst thine earth, Which highte or ev\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuEN1GhCnkrO",
        "colab_type": "code",
        "outputId": "5a7cee13-d595-4b4e-b207-494a97bd2e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Temperature = 0.25\n",
        "total_poem = ['Shall I compare thee to a summer\\'s day?']\n",
        "for i in range(1,11):\n",
        "  total_poem.append(generate_seq(model, mapping, 40, total_poem[i-1], 2000,10,temp=0.25))\n",
        "for l in total_poem:\n",
        "  print(l)\n",
        "  # print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shall I compare thee to a summer's day?\n",
            "Why should in this thy show me despeci\n",
            "st, But the world with the sun a worth of thee,\n",
            "That thou art thou art thou art thou sight, A\n",
            "d thou shalt to the same and the worl's fa\n",
            "e, And thou art thou art thou hast thou ther\n",
            ", The earth spend of the sun in the fair, A\n",
            "d the worth of the world with the sun and la\n",
            "d, That thou art thou art thou didst that I no\n",
            " so, He love doth shadows to the pa\n",
            "nting thee, That in the store to my sel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edYrbnq4Bb9u",
        "colab_type": "text"
      },
      "source": [
        "# Generate haikus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYCYope4Bdt_",
        "colab_type": "code",
        "outputId": "4a5c41d9-a142-4f13-be25-757d95540846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Generate poem line-by-line\n",
        "total_poem = ['The Old Pond ']\n",
        "# for i in range(1,11):\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[0], 2000,5)) # 5 syllablues\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[1], 2000,7)) # 7 syllables\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[2], 2000,5))  # 5 syllablues\n",
        "# total_poem[1] = total_poem[0] + total_poem[1]\n",
        "# total_poem = total_poem[1:]\n",
        "for l in total_poem:\n",
        "  print(l)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Old Pond \n",
            "hat thou art thou a\n",
            "l dead, The earth which in the wo\n",
            "th of thy sell, That tho\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kByPoILECgrH",
        "colab_type": "code",
        "outputId": "20eddb66-8b54-46d3-f29b-60916a7ebec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Generate poem line-by-line\n",
        "total_poem = ['Over the Wintry ']\n",
        "# for i in range(1,11):\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[0], 2000,5)) # 5 syllablues\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[1], 2000,7)) # 7 syllables\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[2], 2000,5))  # 5 syllablues\n",
        "# total_poem[1] = total_poem[0] + total_poem[1]\n",
        "# total_poem = total_poem[1:]\n",
        "for l in total_poem:\n",
        "  print(l)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Over the Wintry \n",
            " am add the store,\n",
            "The eyes that thou art thou a\n",
            "t thou art truth, And the \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2s_Vx19ColS",
        "colab_type": "code",
        "outputId": "4a4e4f39-9018-40ad-9139-973d742f0f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Generate poem line-by-line\n",
        "total_poem = ['A Poppy Blooms ']\n",
        "# for i in range(1,11):\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[0], 2000,5)) # 5 syllablues\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[1], 2000,7)) # 7 syllables\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[2], 2000,5))  # 5 syllablues\n",
        "# total_poem[1] = total_poem[0] + total_poem[1]\n",
        "# total_poem = total_poem[1:]\n",
        "for l in total_poem:\n",
        "  print(l)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A Poppy Blooms \n",
            "aty doth which tho\n",
            " might, And thou art thou art tho\n",
            " art thou mayst to my\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg-JoPPRDWc8",
        "colab_type": "code",
        "outputId": "d307bc71-feb1-47bb-9abe-7f251a3caf8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Generate poem line-by-line\n",
        "total_poem = ['']\n",
        "# for i in range(1,11):\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[0], 2000,5)) # 5 syllablues\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[1], 2000,7)) # 7 syllables\n",
        "total_poem.append(generate_seq(model, mapping, 40, total_poem[2], 2000,5))  # 5 syllablues\n",
        "# total_poem[1] = total_poem[0] + total_poem[1]\n",
        "# total_poem = total_poem[1:]\n",
        "for l in total_poem:\n",
        "  print(l)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Coworndered wher\n",
            " I and thou art thou had, I\n",
            "so beauty's true so\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}